---
layout:     post
title:      "HDFS技术文档"
subtitle:   "Hadoop系列之HDFS（hadoop distributed file system)"
date:       2019-8-8 12:30:00
author:     "弦望晦朔"
header-img: "img/post/post-bg-hdfs.jpg"
tags:
    - 大数据
    - 技术文档
    - Hadoop

---



# 前言

在本文档中，我会先对**Hadoop**进行一个简要的介绍（主要关于“它是什么，解决什么样问题”），并对**Hadoop**的三大构件：`HDFS`,`Yarn`和`MapReduce`进行简要的描述，然后在这一章内，重点介绍`HDFS`的运作机制，主要有关于`HDFS`读写，`NameNode`和`SecondaryNameNode`及`DataNode`，最后再对`HA`进行介绍。



# Hadoop概述

## 什么是Hadoop？

>The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.
>
>
>
>The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.



简而言之，**Hadoop**是一个针对于大数据集进行分布式存储和计算的框架。





## Hadoop解决的问题

### 1.数据的存储与分析——HDFS与MapReduce

### 2.数据的查询——MapReduce

### 3.基于批处理之上

支持Interactive SQL，Iterative processing（基于Spark），Stream processing(基于Storm，Spark)，Search（如Solr）





## Hadoop的组成

**Hadoop**由三部分组成：`HDFS(Hadoop Distributed File System)`，`Yarn(Yet Another Resource Negotiator)`以及`MapReduce`。

简要来说，`HDFS`负责数据的存储，`Yarn`负责资源的调配，`MapReduce`负责数据的计算。



# HDFS

## HDFS概述

![HDFS-1](/img/post/hdfs/hdfs-1.png)

*图1 HDFS概述图*



## HDFS组成架构

HDFS主要由四部分组成：Client、NameNode（NN）、DataNode（DN）和Secondary NameNode（2NN）。



### NameNode(NN)

NameNode主要有4个职责：管理HDFS的名称空间、配置副本策略、管理数据块（Block）的映射信息以及处理客户端读写请求，简而言之，NameNode是所有数据的索引，所有的文件通过它来进行寻址以进行读写操作。



### Secondary NameNode（2NN）

辅助NameNode，分担工作量，定期合并Fsimage和Edits，推送给NameNode，Secondary NameNode并非NameNode的热备，不能马上替换NameNode并提供服务。



### DataNode（DN）

DataNode通过听取NameNode的指令来进行实际的操作，一般来说，有两个功能：存储实际的数据块、执行数据块的读/写操作。DataNode中的文件通过块（Block）来存储，hadoop2.x版本中默认大小为128M，老版本64M，块的大小可以通过配置参数(dfs.blocksize)来规定。



### Client

Client共4个功能，首先，HDFS是分布式存储，面对超大文件，节点无法整存，Client把这种文件切块存到不同节点，其次，它与NameNode交互，获取文件的位置信息，进而与DataNode交互，读取或写入数据，第三点，它提供命令管理HDFS，格式化NameNode，最后，它提供命令访问HDFS，提供增删改查的功能。



## HDFS读写流程

![HDFS-2](/img/post/hdfs/hdfs-2.png)

*图2 HDFS写流程*



DataNode的选择依据网络拓扑距离最近的原则，最短路径算法,网上延迟时间少,传输速率高。依据节点（Node），机架（Rack）和数据中心（Data Center）进行计算。





## NameNode与Secondary NameNode工作机制

### 概述

NN元数据共两份（内存存在一份，磁盘中FsImage存在一份），但如果全部一起更新，效率太低，因此引入Edits文件（只进行追加操作），2NN定时将FsImage和Edits合并，并传入NN中，形成新的FsImage。

**Fsimage**：NameNode内存中元数据序列化后形成的文件。包含文件系统所有目录和inode的序列化信息。

**Edits：**记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。

**CheckPoint:**通常情况下，SecondaryNameNode每隔一小时执行一次，同时，一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次，可通过`hdfs-default.xml`修改。



**如何查看Fsimage和Edits文件：**

hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径

hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径



### 详细工作机制

#### 第一阶段：NameNode启动

1.第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。
		2.客户端对元数据进行增删改的请求。
		3.NameNode记录操作日志，更新滚动日志。
		4.NameNode在内存中对元数据进行增删改。



#### 第二阶段：Secondary NameNode工作

1.Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。
		2.Secondary NameNode请求执行CheckPoint。
		3.NameNode滚动正在写的Edits日志。
		4.将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。
		5.Secondary NameNode加载编辑日志和镜像文件到内存，并合并。
		6.生成新的镜像文件fsimage.chkpoint。
		7.拷贝fsimage.chkpoint到NameNode。
		8.NameNode将fsimage.chkpoint重新命名成fsimage。
		9.Edits也清空



![HDFS-3](/img/post/hdfs/hdfs-3.png)

*图3 NN与2NN运作流程图*



## DataNode存储详解

### DataNode工作机制

1.DataNode启动，向NameNode注册
		2.注册成功后每1小时为一个周期，上报所有块信息
		3.在平时，每3秒有一次心跳，心跳返回结果带有NameNode给DataNode的指令



![HDFS-4](/img/post/hdfs/hdfs-4.png)

*图4 DataNode工作机制*



### 如何保证数据完整性

DataNode读取Block的时候，计算CheckSum，一致则进行读取，不一致则计算其他存有该Block的CheckSum，DataNode周期性的验证CheckSum。



### 掉线参数设置

1.DataNode进程死亡或者网络故障造成DataNode与NameNode无法通信

2.NameNode不会立刻判定死亡，而要等待超时时长

3.超时时长默认为10分钟+30秒

4.超时时间为TimeOut

`TimeOut = 2 * dfs.namenode.heartbeat.recheck-interval + 10 * dfs.heartbeat.interval`

上述两项可在`hdfs-site.xml`中进行设置：

```xml
<property>
    <name>dfs.namenode.heartbeat.recheck-interval</name>
    <value>300000</value> //单位为毫秒
</property>
<property>
    <name>dfs.heartbeat.interval</name>
    <value>3</value>  //单位为秒
</property>
```



## HDFS HA配置

### 概述

HA即（High Availablity），即高可用，它的关键策略在于消除单点故障，严格来说HA分为HDFS的HA和YARN的HA。

HDFS的HA思路是通过配置Active/Standby两个NameNode，形成热备。

具体实践方法有NFS（Network File System）和QJM（Quorum Journal Manager），主流使用QJM，因为NFS相对于QJM而言不够稳定。

QJM是一个集群（Cluster），通过该集群存储Active/Standy的两个NameNode的数据。



### 工作机制

HDFS HA主要依赖于两个核心机制，第一个即基于QJM的Edits文件管理系统，共享两个NameNode的文件存储，第二个即依赖于Zookeeper的故障转移机制，通过建立Zkfc（Zookeeper Failover Controller）与Zookeeper和NameNode进行连接。

![HDFS-5](/img/post/hdfs/hdfs-5.png)

*图5 HDFS HA 工作机制*





